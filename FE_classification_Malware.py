# -*- coding: utf-8 -*-
"""
Created on Mon Jan 28 09:05:56 2019

@author: wmy
"""

import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
import lightgbm as lgb
from sklearn.model_selection import KFold
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import multiprocessing
from sklearn.impute import SimpleImputer
from category_encoders.leave_one_out import LeaveOneOutEncoder
#import warnings

#import sys

#import matplotlib.pyplot as plt
#import seaborn as sns
from sklearn.metrics import roc_auc_score
np.random.seed(4590)
import gc
num_cores = multiprocessing.cpu_count()

def reduce_mem_usage(df, verbose=True):
    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
    start_mem = df.memory_usage().sum() / 1024**2    
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)    
    end_mem = df.memory_usage().sum() / 1024**2
    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))
    return df


def group_mean(group):
   group_size = float(group.shape[0])
   return (group.mean() * group_size + global_mean) / group_size
#    else:
#        return (group.mean() * group_size + global_mean * C) / (group_size + C)
#

def targetencode(column):
   tmap=target.groupby(column).mean().to_dict()
   return column.map(tmap)
   
def targetencode(column):
   tmap=train[['HasDetections',column]].groupby(column).mean().to_dict()
   missing = np.mean(np.array(list(tmap['HasDetections'].values())))
   train[column]=train[column].apply(lambda x : tmap['HasDetections'].get(x, missing))
   test[column]=test[column].apply(lambda x : tmap['HasDetections'].get(x, missing))

def targetencode(column):
   tlen=len(target)
   workdf=pd.DataFrame([column[:tlen], target])
   cname=workdf.columns[0]
   tname=workdf.columns[1]
   means_dict={}
   group = workdf[[cname, tname]].groupby(cname).mean()
   means_dict[cname] = group.to_dict() 
   missing = np.mean(np.array(list(means_dict[cname][tname].values())))
   return alldata[cname].apply(lambda x : means_dict[cname][tname].get(x, missing))

def factencode(coll):
   _, idx = pd.factorize(coll)
   coll = pd.Series(idx.get_indexer(coll)).astype('category')
   return coll

def splitAassemble(x,delimit,assnum):
    if type(x)==float:
       return x
    else:
        x.lower()
        parts=x.split(delimit)
        if len(parts)==1:
            return x
        x=parts[0]
        for i in range(assnum-1):
            x += '_'
            x += parts[i+1]        
    return x
train['Census_OSBranch']=train['Census_OSBranch'].apply(lambda x: splitAassemble(x,'_',2))
test['Census_OSBranch']=test['Census_OSBranch'].apply(lambda x: splitAassemble(x,'_',2))

def extractserver(x):
    if 'SERVER' in x:
        x='SERVER'
    else:
        x=x[:4]
    return x
train['Census_OSSkuName']=train['Census_OSSkuName'].apply(lambda x: extractserver(x)).replace('PRO_','PROF')

def group_battery(x):
    x = str(x).lower()
    if 'li' in x:
        return 1
    else:
        return 0 
train['Census_InternalBatteryType'] = train['Census_InternalBatteryType'].apply(group_battery).astype('category')



def fillmean(col):
   col=col.astype(float).fillna(col.astype(float).dropna().mean())
   return col
def fillquantile(col):
   col=col.astype(float).fillna(col.dropna().astype(float).quantile(q=0.5))
   return col

def tight_identifier(col,name,thresh):
    newname=name+'_count'
    browser=pd.DataFrame(col).astype(str).groupby(name)[name].agg('count')
    browser=pd.DataFrame(browser)
    browser.columns=[newname]
    browser=browser.sort_values(newname,ascending=False)
#    browser.columns=['counts']
    browser.reset_index(inplace=True)
    browser['new']=browser[name]
    browser.loc[browser[newname]<thresh,'new']='others'
    browser.drop(newname,axis=1,inplace=True)
#    browser=browser[1:]
    browsermap={str(b[0]):str(b[1]) for i,b in browser.iterrows()}
    col=col.astype(str).map(browsermap).fillna('N').astype('category')
    _, indexer = pd.factorize(col)
    col = pd.Series(indexer.get_indexer(col)).astype('category')
    return col
#OsSuite#14level
alldata['OsSuite']=tight_identifier(alldata['OsSuite'],'OsSuite',100)
#LocaleEnglishNameIdentifier#276level
alldata['LocaleEnglishNameIdentifier']=tight_identifier(alldata['LocaleEnglishNameIdentifier'],'LocaleEnglishNameIdentifier',100000)


#-------------convert version number
version_cols=['OsVer','AvSigVersion','EngineVersion','AppVersion','Census_OSVersion']
alldata.loc[5244810,'AvSigVersion']='1.217.1144.0'
def v2n(x,mlen):
    xlen=x.split('.')
    for i in range(len(mlen)):
        xlen[i]=xlen[i].zfill(int(mlen[i]-len(xlen[i])))
    return ''.join(xlen)
for v in version_cols:
    alen=len(alldata.loc[0,v].split('.'))
    maxlen=np.zeros(alen)
    for i in range(alen):
        maxlen[i]=max(alldata[v].apply(lambda x: len(x.split('.')[i])))
    alldata[v]=alldata[v].apply(lambda x: v2n(x,maxlen)).astype(float)
    print(v)

